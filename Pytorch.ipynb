{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyND6Jwd77s1ltLXBaH0hi/l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yiting916/GCP/blob/main/Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 安裝相關套件\n",
        "\n"
      ],
      "metadata": {
        "id": "B3uvvf3PM5ep"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yuxzN21NJkUA",
        "outputId": "482bdcc0-51da-4bab-8196-552030b1ebb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.5/173.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.1/212.1 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.0/322.0 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.3/211.3 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.5/274.5 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.1/526.1 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.5/261.5 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for google-apitools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "distributed 2024.12.1 requires cloudpickle>=3.0.0, but you have cloudpickle 2.2.1 which is incompatible.\n",
            "dask 2024.12.1 requires cloudpickle>=3.0.0, but you have cloudpickle 2.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install apache_beam[gcp,dataframe] --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install torch --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "cVjuY4D3LavB",
        "outputId": "593b8716-2f97-471a-e0ad-79cb338c977e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m92.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 導入應用的模組"
      ],
      "metadata": {
        "id": "X_Ji6fB5MzjL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import csv\n",
        "import json\n",
        "import os\n",
        "import torch\n",
        "from typing import Tuple\n",
        "\n",
        "import apache_beam as beam\n",
        "import numpy\n",
        "from apache_beam.io.gcp.bigquery import ReadFromBigQuery\n",
        "from apache_beam.ml.inference.base import KeyedModelHandler\n",
        "from apache_beam.ml.inference.base import PredictionResult\n",
        "from apache_beam.ml.inference.base import RunInference\n",
        "from apache_beam.dataframe.convert import to_pcollection\n",
        "from apache_beam.ml.inference.pytorch_inference import PytorchModelHandlerTensor\n",
        "from apache_beam.ml.inference.pytorch_inference import PytorchModelHandlerKeyedTensor\n",
        "from apache_beam.options.pipeline_options import PipelineOptions\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "metadata": {
        "id": "B_oq-JF0MxGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 授予Colab筆記本訪問管理GCP權限\n"
      ],
      "metadata": {
        "id": "iGBMc5IFNCVi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n"
      ],
      "metadata": {
        "id": "jKkkB_VYNCqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 定義GCP使用的專案及值區"
      ],
      "metadata": {
        "id": "GKvHcQksNJDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 定義常數（Constants）\n",
        "project = \"專案 ID\"\n",
        "bucket = \"值區 ID\"  # bucket ID\n",
        "\n",
        "# 設定專案 ID。\n",
        "os.environ['GOOGLE_CLOUD_PROJECT'] = project\n",
        "\n",
        "# 儲存模型的路徑\n",
        "save_model_dir_multiply_five = 'five_times_table_torch.pt'\n",
        "save_model_dir_multiply_ten = 'ten_times_table_torch.pt'\n",
        "\n"
      ],
      "metadata": {
        "id": "45omOCJ9NMHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 建立Pytorch線性迴歸模型"
      ],
      "metadata": {
        "id": "bJjppkiRNb9Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "建立線性迴歸模型"
      ],
      "metadata": {
        "id": "ANttqyKbNlJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegression(torch.nn.Module):\n",
        "    def __init__(self, input_dim=1, output_dim=1):\n",
        "        super().__init__()\n",
        "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
        "    def forward(self, x):\n",
        "        out = self.linear(x)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "_rdsdlPBNevg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "準備測試資料確認模型狀況"
      ],
      "metadata": {
        "id": "KDIC-q99Nn8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = numpy.arange(0, 100, dtype=numpy.float32).reshape(-1, 1)\n",
        "y = (x * 5).reshape(-1, 1)\n",
        "value_to_predict = numpy.array([20, 40, 60, 90], dtype=numpy.float32).reshape(-1, 1)\n"
      ],
      "metadata": {
        "id": "hfIKtzioNrat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "測試 5 time資料\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NMyWq5M-Nulj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "five_times_model = LinearRegression()\n",
        "optimizer = torch.optim.Adam(five_times_model.parameters())\n",
        "loss_fn = torch.nn.L1Loss()\n",
        "\n",
        "\"\"\"\n",
        "Train the five_times_model\n",
        "\"\"\"\n",
        "epochs = 10000\n",
        "tensor_x = torch.from_numpy(x)\n",
        "tensor_y = torch.from_numpy(y)\n",
        "for epoch in range(epochs):\n",
        "    y_pred = five_times_model(tensor_x)\n",
        "    loss = loss_fn(y_pred, tensor_y)\n",
        "    five_times_model.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n"
      ],
      "metadata": {
        "id": "eruC0FufNwtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "使用torch.save()儲存模型"
      ],
      "metadata": {
        "id": "n0ETSGa0N2Mi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(five_times_model.state_dict(), save_model_dir_multiply_five)\n",
        "print(os.path.exists(save_model_dir_multiply_five)) # Verify that the model is saved.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YH77xtMCN3Or",
        "outputId": "e9ffc855-0c80-4e58-f709-7a4ed0560341"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "測試10 time資料\n",
        "\n"
      ],
      "metadata": {
        "id": "SuOSerrYN6PZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ten_times_model = LinearRegression()\n",
        "optimizer = torch.optim.Adam(ten_times_model.parameters())\n",
        "loss_fn = torch.nn.L1Loss()\n",
        "\n",
        "epochs = 10000\n",
        "tensor_x = torch.from_numpy(x)\n",
        "tensor_y = torch.from_numpy(y)\n",
        "for epoch in range(epochs):\n",
        "    y_pred = ten_times_model(tensor_x)\n",
        "    loss = loss_fn(y_pred, tensor_y)\n",
        "    ten_times_model.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n"
      ],
      "metadata": {
        "id": "btcMWN_PN52p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "儲存模型"
      ],
      "metadata": {
        "id": "k3LMuts2OCsh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(ten_times_model.state_dict(), save_model_dir_multiply_ten)\n",
        "print(os.path.exists(save_model_dir_multiply_ten)) # verify if the model is saved\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qf8ymB9nOEa9",
        "outputId": "96678634-b03b-49d5-9c2f-dd17a6a3e147"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataflow測試 & RunInference預測"
      ],
      "metadata": {
        "id": "LI1MuKqwT7AC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "利用RunInference預測"
      ],
      "metadata": {
        "id": "btYZju1kT_QL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch_five_times_model_handler = PytorchModelHandlerTensor(\n",
        "    state_dict_path=save_model_dir_multiply_five,\n",
        "    model_class=LinearRegression,\n",
        "    model_params={'input_dim': 1,\n",
        "                  'output_dim': 1}\n",
        "                  )\n",
        "pipeline = beam.Pipeline()\n",
        "\n",
        "with pipeline as p:\n",
        "      (\n",
        "      p\n",
        "      | \"ReadInputData\" >> beam.Create(value_to_predict)\n",
        "      | \"ConvertNumpyToTensor\" >> beam.Map(torch.Tensor)\n",
        "      | \"RunInferenceTorch\" >> RunInference(torch_five_times_model_handler)\n",
        "      | beam.Map(print)\n",
        "      )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "_FZk8bNlTa4U",
        "outputId": "5a612ff6-df6f-4ebb-faf3-2e4eceabc562"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
              "          var jqueryScript = document.createElement('script');\n",
              "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
              "          jqueryScript.type = 'text/javascript';\n",
              "          jqueryScript.onload = function() {\n",
              "            var datatableScript = document.createElement('script');\n",
              "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
              "            datatableScript.type = 'text/javascript';\n",
              "            datatableScript.onload = function() {\n",
              "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
              "              window.interactive_beam_jquery(document).ready(function($){\n",
              "                \n",
              "              });\n",
              "            }\n",
              "            document.head.appendChild(datatableScript);\n",
              "          };\n",
              "          document.head.appendChild(jqueryScript);\n",
              "        } else {\n",
              "          window.interactive_beam_jquery(document).ready(function($){\n",
              "            \n",
              "          });\n",
              "        }"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PredictionResult(example=tensor([20.]), inference=tensor([99.9989]), model_id='five_times_table_torch.pt')\n",
            "PredictionResult(example=tensor([40.]), inference=tensor([199.9978]), model_id='five_times_table_torch.pt')\n",
            "PredictionResult(example=tensor([60.]), inference=tensor([299.9968]), model_id='five_times_table_torch.pt')\n",
            "PredictionResult(example=tensor([90.]), inference=tensor([449.9952]), model_id='five_times_table_torch.pt')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "處理RunInference預測結果"
      ],
      "metadata": {
        "id": "SfN75e8MUDip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PredictionProcessor(beam.DoFn):\n",
        "  \"\"\"\n",
        "  用於格式化 RunInference 轉換輸出的處理器。\n",
        "  \"\"\"\n",
        "  def process(\n",
        "      self,\n",
        "      element: PredictionResult):\n",
        "    input_value = element.example\n",
        "    output_value = element.inference\n",
        "    yield (f\"輸入值為 {input_value.item()}，輸出值為 {output_value.item()}\")\n",
        "\n",
        "pipeline = beam.Pipeline()\n",
        "\n",
        "with pipeline as p:\n",
        "    (\n",
        "    p\n",
        "    | \"讀取輸入資料\" >> beam.Create(value_to_predict)\n",
        "    | \"將 Numpy 轉換為 Tensor\" >> beam.Map(torch.Tensor)\n",
        "    | \"執行 Torch 推論\" >> RunInference(torch_five_times_model_handler)\n",
        "    | \"後處理預測結果\" >> beam.ParDo(PredictionProcessor())\n",
        "    | beam.Map(print)\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9dP_vRyTrP9",
        "outputId": "df63e2c7-786c-4d0a-a540-ed9822064f73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "輸入值為 20.0，輸出值為 99.99889373779297\n",
            "輸入值為 40.0，輸出值為 199.9978485107422\n",
            "輸入值為 60.0，輸出值為 299.9967956542969\n",
            "輸入值為 90.0，輸出值為 449.9952087402344\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 建立鍵值資料格式"
      ],
      "metadata": {
        "id": "60MOhqutWyKF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PredictionWithKeyProcessor(beam.DoFn):\n",
        "    def __init__(self):\n",
        "        beam.DoFn.__init__(self)\n",
        "\n",
        "    def process(\n",
        "          self,\n",
        "          element: Tuple[str, PredictionResult]):\n",
        "        key = element[0]\n",
        "        input_value = element[1].example\n",
        "        output_value = element[1].inference\n",
        "        yield (f\"key: {key}, input: {input_value.item()} output: {output_value.item()}\" )\n"
      ],
      "metadata": {
        "id": "uafs6R79W_NQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 更新 BigQuery 模組"
      ],
      "metadata": {
        "id": "zJxdRt7AXDSM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade google-cloud-bigquery --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvKUt7QcXJeR",
        "outputId": "ef9556b6-4e29-48d8-ad60-13b283dbcf62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/247.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.6/247.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.9/247.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 設定專案指向"
      ],
      "metadata": {
        "id": "Ai56SFXvXNMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud config set project $project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaRTGJG9XO5a",
        "outputId": "d01a0f90-4213-406c-8458-62fd89980138"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 透過 BigQuery SDK 建立資料集和資料表"
      ],
      "metadata": {
        "id": "RNDCe7t1XhJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "client = bigquery.Client(project=project)\n",
        "\n",
        "# 確保 dataset_id 在專案中是唯一的。\n",
        "dataset_id = '{project}.maths'.format(project=project)\n",
        "dataset = bigquery.Dataset(dataset_id)\n",
        "\n",
        "# 根據專案配置修改位置。\n",
        "dataset.location = 'US'\n",
        "dataset = client.create_dataset(dataset, exists_ok=True)\n",
        "\n",
        "# BigQuery 資料集中的資料表名稱。\n",
        "table_name = 'maths_problems_1'\n",
        "\n",
        "query = \"\"\"\n",
        "    CREATE OR REPLACE TABLE\n",
        "      {project}.maths.{table} ( key STRING OPTIONS(description=\"A unique key for the maths problem\"),\n",
        "    value FLOAT64 OPTIONS(description=\"Our maths problem\" ) );\n",
        "    INSERT INTO maths.{table}\n",
        "    VALUES\n",
        "      (\"first_question\", 105.00),\n",
        "      (\"second_question\", 108.00),\n",
        "      (\"third_question\", 1000.00),\n",
        "      (\"fourth_question\", 1013.00)\n",
        "\"\"\".format(project=project, table=table_name)\n",
        "\n",
        "create_job = client.query(query)\n",
        "create_job.result()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIuLwV1lXve1",
        "outputId": "e3b69313-603c-4e88-dd8d-05fd3de67f32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<google.cloud.bigquery.table._EmptyRowIterator at 0x7fd71fe23910>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 法1:從 BigQuery抓取資料預測"
      ],
      "metadata": {
        "id": "23Glek7tYtwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_options = PipelineOptions().from_dictionary({'temp_location':f'gs://{bucket}/tmp',\n",
        "                                                      })\n",
        "pipeline = beam.Pipeline(options=pipeline_options)\n",
        "\n",
        "keyed_torch_five_times_model_handler = KeyedModelHandler(torch_five_times_model_handler)\n",
        "\n",
        "table_name = 'maths_problems_1'\n",
        "table_spec = f'{project}:maths.{table_name}'\n",
        "\n",
        "with pipeline as p:\n",
        "      (\n",
        "      p\n",
        "      | \"ReadFromBQ\" >> beam.io.ReadFromBigQuery(table=table_spec)\n",
        "      | \"PreprocessData\" >> beam.Map(lambda x: (x['key'], x['value']))\n",
        "      | \"ConvertNumpyToTensor\" >> beam.Map(lambda x: (x[0], torch.Tensor([x[1]])))\n",
        "      | \"RunInferenceTorch\" >> RunInference(keyed_torch_five_times_model_handler)\n",
        "      | \"PostProcessPredictions\" >> beam.ParDo(PredictionWithKeyProcessor())\n",
        "      | beam.Map(print)\n",
        "      )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4q0noAAYp9u",
        "outputId": "ef31aa82-9121-45e1-a1a5-a65f677d42a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'apache_beam.io.gcp.bigquery_read_internal._PassThroughThenCleanup.expand.<locals>.RemoveExtractedFiles'>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "key: first_question, input: 105.0 output: 524.9944458007812\n",
            "key: third_question, input: 1000.0 output: 4999.94775390625\n",
            "key: second_question, input: 108.0 output: 539.9942626953125\n",
            "key: fourth_question, input: 1013.0 output: 5064.94677734375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 法2: 建立含鍵值的 CSV 範例檔案"
      ],
      "metadata": {
        "id": "NGrcU2OGZTiB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 建立CSV範例資料\n",
        "csv_values = [(\"first_question\", 105.00),\n",
        "      (\"second_question\", 108.00),\n",
        "      (\"third_question\", 1000.00),\n",
        "      (\"fourth_question\", 1013.00)]\n",
        "input_csv_file = \"./maths_problem.csv\"\n",
        "\n",
        "with open(input_csv_file, 'w') as f:\n",
        "  writer = csv.writer(f)\n",
        "  writer.writerow(['key', 'value'])\n",
        "  for row in csv_values:\n",
        "    writer.writerow(row)\n",
        "\n",
        "assert os.path.exists(input_csv_file) == True\n"
      ],
      "metadata": {
        "id": "ZPwrgobLZYoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 抓取 csv 檔資料進行預測"
      ],
      "metadata": {
        "id": "k196m3Eaapyg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_options = PipelineOptions().from_dictionary({'temp_location':f'gs://{bucket}/tmp',\n",
        "                                                      })\n",
        "pipeline = beam.Pipeline(options=pipeline_options)\n",
        "\n",
        "keyed_torch_five_times_model_handler = KeyedModelHandler(torch_five_times_model_handler)\n",
        "\n",
        "with pipeline as p:\n",
        "  df = p | beam.dataframe.io.read_csv(input_csv_file)\n",
        "  pc = to_pcollection(df)\n",
        "  (pc\n",
        "    | \"ConvertNumpyToTensor\" >> beam.Map(lambda x: (x[0], torch.Tensor([x[1]])))\n",
        "    | \"RunInferenceTorch\" >> RunInference(keyed_torch_five_times_model_handler)\n",
        "    | \"PostProcessPredictions\" >> beam.ParDo(PredictionWithKeyProcessor())\n",
        "    | beam.Map(print)\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxMuaxbIatUs",
        "outputId": "6bf5164a-6556-4da1-de11-6b6b5808da15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "key: first_question, input: 105.0 output: 524.9944458007812\n",
            "key: second_question, input: 108.0 output: 539.9942626953125\n",
            "key: third_question, input: 1000.0 output: 4999.94775390625\n",
            "key: fourth_question, input: 1013.0 output: 5064.94677734375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 法3: 單一管道多模型資源預測"
      ],
      "metadata": {
        "id": "ktDBOXrxbMDH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 建立2個模型: 5 times & 10 times\n",
        "torch_ten_times_model_handler = PytorchModelHandlerTensor(state_dict_path=save_model_dir_multiply_ten,\n",
        "                                        model_class=LinearRegression,\n",
        "                                        model_params={'input_dim': 1,\n",
        "                                                      'output_dim': 1}\n",
        "                                        )\n",
        "keyed_torch_ten_times_model_handler = KeyedModelHandler(torch_ten_times_model_handler)\n"
      ],
      "metadata": {
        "id": "re9ZT-zdbSU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "建立管道抓取多模型預測"
      ],
      "metadata": {
        "id": "4QugX_TPc6ac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 管線初始化與讀取資料\n",
        "pipeline_options = PipelineOptions().from_dictionary(\n",
        "                                      {'temp_location':f'gs://{bucket}/tmp'})\n",
        "\n",
        "pipeline = beam.Pipeline(options=pipeline_options)\n",
        "\n",
        "read_from_bq = beam.io.ReadFromBigQuery(table=table_spec)\n",
        "\n",
        "with pipeline as p:\n",
        "  # 第一條推論管線（乘以 5）\n",
        "  multiply_five = (\n",
        "      p   # 並行處理\n",
        "      |  read_from_bq\n",
        "      | \"CreateMultiplyFiveTuple\" >> beam.Map(lambda x: ('{} {}'.format(x['key'], '* 5'), x['value']))\n",
        "      | \"ConvertNumpyToTensorFiveTuple\" >> beam.Map(lambda x: (x[0], torch.Tensor([x[1]])))\n",
        "      | \"RunInferenceTorchFiveTuple\" >> RunInference(keyed_torch_five_times_model_handler)\n",
        "  )\n",
        "  # 第二條推論管線（乘以 10）\n",
        "  multiply_ten = (\n",
        "      p   # 並行處理\n",
        "      | read_from_bq\n",
        "      | \"CreateMultiplyTenTuple\" >> beam.Map(lambda x: ('{} {}'.format(x['key'], '* 10'), x['value']))\n",
        "      | \"ConvertNumpyToTensorTenTuple\" >> beam.Map(lambda x: (x[0], torch.Tensor([x[1]])))\n",
        "      | \"RunInferenceTorchTenTuple\" >> RunInference(keyed_torch_ten_times_model_handler)\n",
        "  )\n",
        "  # 合併與處理最終結果\n",
        "  inference_result = ((multiply_five, multiply_ten) | beam.Flatten()\n",
        "                                 | beam.ParDo(PredictionWithKeyProcessor()))\n",
        "  inference_result | beam.Map(print)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06Jp45DUb3zY",
        "outputId": "f63007da-84df-4068-9663-c8d0fa85fe76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'apache_beam.io.gcp.bigquery_read_internal._PassThroughThenCleanup.expand.<locals>.RemoveExtractedFiles'>)\n",
            "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'apache_beam.io.gcp.bigquery_read_internal._PassThroughThenCleanup.expand.<locals>.RemoveExtractedFiles'>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "key: first_question * 5, input: 105.0 output: 524.9944458007812\n",
            "key: third_question * 5, input: 1000.0 output: 4999.94775390625\n",
            "key: second_question * 5, input: 108.0 output: 539.9942626953125\n",
            "key: fourth_question * 5, input: 1013.0 output: 5064.94677734375\n",
            "key: first_question * 10, input: 105.0 output: 524.9898071289062\n",
            "key: third_question * 10, input: 1000.0 output: 4999.904296875\n",
            "key: second_question * 10, input: 108.0 output: 539.989501953125\n",
            "key: fourth_question * 10, input: 1013.0 output: 5064.90283203125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "依序使用多模型預測"
      ],
      "metadata": {
        "id": "bJpRtvxhcgNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_interim_inference(element):\n",
        "    key, prediction_result = element\n",
        "    input_value = prediction_result.example\n",
        "    inference = prediction_result.inference\n",
        "    formatted_input_value = 'original input is `{} {}`'.format(key, input_value)\n",
        "    return formatted_input_value, inference\n",
        "\n",
        "\n",
        "pipeline_options = PipelineOptions().from_dictionary(\n",
        "                                      {'temp_location':f'gs://{bucket}/tmp'})\n",
        "pipeline = beam.Pipeline(options=pipeline_options)\n",
        "\n",
        "with pipeline as p:\n",
        "  multiply_five = (\n",
        "      p\n",
        "      | beam.io.ReadFromBigQuery(table=table_spec)\n",
        "      | \"CreateMultiplyFiveTuple\" >> beam.Map(lambda x: (x['key'], x['value']))\n",
        "      | \"ConvertNumpyToTensorFiveTuple\" >> beam.Map(lambda x: (x[0], torch.Tensor([x[1]])))\n",
        "      | \"RunInferenceTorchFiveTuple\" >> RunInference(keyed_torch_five_times_model_handler)\n",
        "  )\n",
        "\n",
        "  inference_result = (\n",
        "    multiply_five # 無p --> 依序處理\n",
        "      | \"ExtractResult\" >> beam.Map(process_interim_inference)\n",
        "      | \"RunInferenceTorchTenTuple\" >> RunInference(keyed_torch_ten_times_model_handler)\n",
        "      | beam.ParDo(PredictionWithKeyProcessor())\n",
        "    )\n",
        "  inference_result | beam.Map(print)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuV_pPQPcdj0",
        "outputId": "5b3d8c4d-7b5c-468d-ae63-b25ee17cab38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'apache_beam.io.gcp.bigquery_read_internal._PassThroughThenCleanup.expand.<locals>.RemoveExtractedFiles'>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "key: original input is `first_question tensor([105.])`, input: 524.9944458007812 output: 2624.921630859375\n",
            "key: original input is `third_question tensor([1000.])`, input: 4999.94775390625 output: 24999.259765625\n",
            "key: original input is `second_question tensor([108.])`, input: 539.9942626953125 output: 2699.91943359375\n",
            "key: original input is `fourth_question tensor([1013.])`, input: 5064.94677734375 output: 25324.248046875\n"
          ]
        }
      ]
    }
  ]
}