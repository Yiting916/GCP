{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO7HwIVgPEQBjPXTcAntjE2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yiting916/GCP/blob/main/scikit_learn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "安裝Dataflow、Pubsub、Bigquery等SDK模組"
      ],
      "metadata": {
        "id": "2iEPUc4dfAZg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ObAH3K6e4IU",
        "outputId": "18596b00-b19f-4d3c-e3dd-917fb164fbeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.5/173.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.1/212.1 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.0/322.0 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.3/211.3 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.5/274.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.1/526.1 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.5/261.5 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for google-apitools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "distributed 2024.12.1 requires cloudpickle>=3.0.0, but you have cloudpickle 2.2.1 which is incompatible.\n",
            "dask 2024.12.1 requires cloudpickle>=3.0.0, but you have cloudpickle 2.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install google-api-core --quiet\n",
        "!pip install google-cloud-pubsub google-cloud-bigquery-storage --quiet\n",
        "!pip install apache-beam[gcp,dataframe] --quiet\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "授予Colab筆記本訪問管理GCP權限"
      ],
      "metadata": {
        "id": "7uwL7iIDfLRV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n"
      ],
      "metadata": {
        "id": "wBnAQQEIfKjO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "導入實驗所需模組"
      ],
      "metadata": {
        "id": "nIMAcU9BfS30"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from sklearn import linear_model\n",
        "from typing import Tuple\n",
        "\n",
        "import numpy as np\n",
        "import apache_beam as beam\n",
        "\n",
        "from apache_beam.ml.inference.sklearn_inference import ModelFileType\n",
        "from apache_beam.ml.inference.sklearn_inference import SklearnModelHandlerNumpy\n",
        "from apache_beam.ml.inference.base import KeyedModelHandler\n",
        "from apache_beam.ml.inference.base import PredictionResult\n",
        "from apache_beam.ml.inference.base import RunInference\n",
        "from apache_beam.options.pipeline_options import PipelineOptions\n"
      ],
      "metadata": {
        "id": "NBBahaWzfPyp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 定義常數: 設定專案/值區 ID"
      ],
      "metadata": {
        "id": "ZL6Ztv5Kf8hM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# 定義常數（Constants）\n",
        "project = \"tibame-gad245-14-0319\"\n",
        "bucket = \"tibame-gad245-14-0319\"\n",
        "\n",
        "# 設定專案 ID。\n",
        "os.environ['GOOGLE_CLOUD_PROJECT'] = project"
      ],
      "metadata": {
        "id": "oGi3OkYGgD4B"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 建立 scikit-learn 模型"
      ],
      "metadata": {
        "id": "tnE109AsgW4K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "建立線性迴歸模型"
      ],
      "metadata": {
        "id": "cLBBnnxNgnWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 準備訓練 sklearn 模型的輸入資料（5 倍表）。\n",
        "x = np.arange(0, 100, dtype=np.float32).reshape(-1, 1)\n",
        "y = (x * 5).reshape(-1, 1)\n",
        "\n",
        "def train_and_save_model(x, y, model_file_name):\n",
        "  \"\"\"訓練線性回歸模型並儲存至檔案。\"\"\"\n",
        "  regression = linear_model.LinearRegression()\n",
        "  regression.fit(x, y)\n",
        "\n",
        "  with open(model_file_name, 'wb') as f:\n",
        "      pickle.dump(regression, f)\n",
        "\n",
        "# 訓練並儲存 5 倍表模型。\n",
        "five_times_model_filename = 'sklearn_5x_model.pkl'\n",
        "train_and_save_model(x, y, five_times_model_filename)\n",
        "\n",
        "# 訓練並儲存 10 倍表模型。\n",
        "ten_times_model_filename = 'sklearn_10x_model.pkl'\n",
        "train_and_save_model(x, y, ten_times_model_filename)\n",
        "y = (x * 10).reshape(-1, 1)\n",
        "train_and_save_model(x, y, 'sklearn_10x_model.pkl')\n",
        "\n"
      ],
      "metadata": {
        "id": "zDlcYk1igaQk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataflow 測試"
      ],
      "metadata": {
        "id": "coraARC2h2gR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "建立 BigQuey 資料來源"
      ],
      "metadata": {
        "id": "zUFg1aVVh86a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade google-cloud-bigquery --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caekAhtShw5K",
        "outputId": "7600966e-d53e-4f55-f0f9-5c7150470942"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/247.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/247.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.9/247.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud config set project $project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoIrYu-jh6OB",
        "outputId": "28e887c7-2570-4f7f-c3ac-d7068f6f29b0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 將資料填入 BigQuery 資料表\n",
        "\n",
        "from google.cloud import bigquery\n",
        "\n",
        "client = bigquery.Client(project=project)\n",
        "\n",
        "# 確保 dataset_id 在專案中是唯一的。\n",
        "dataset_id = '{project}.maths'.format(project=project)\n",
        "dataset = bigquery.Dataset(dataset_id)\n",
        "\n",
        "# 根據專案設定修改位置。\n",
        "dataset.location = 'US'\n",
        "dataset = client.create_dataset(dataset, exists_ok=True)\n",
        "\n",
        "# BigQuery 資料集中的資料表名稱。\n",
        "table_name = 'maths_problems_1'\n",
        "\n",
        "query = \"\"\"\n",
        "    CREATE OR REPLACE TABLE\n",
        "      {project}.maths.{table} ( key STRING OPTIONS(description=\"A unique key for the maths problem\"),\n",
        "    value FLOAT64 OPTIONS(description=\"Our maths problem\" ) );\n",
        "    INSERT INTO maths.{table}\n",
        "    VALUES\n",
        "      (\"first_example\", 105.00),\n",
        "      (\"second_example\", 108.00),\n",
        "      (\"third_example\", 1000.00),\n",
        "      (\"fourth_example\", 1013.00)\n",
        "\"\"\".format(project=project, table=table_name)\n",
        "\n",
        "create_job = client.query(query)\n",
        "create_job.result()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiacPgBKiEfD",
        "outputId": "ae7453fa-cccd-4928-c445-6bff6c0a540d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<google.cloud.bigquery.table._EmptyRowIterator at 0x7c8b755e4d10>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 法1: 讀取 BigQuery 資料進行預測"
      ],
      "metadata": {
        "id": "NC1vInhFg2ta"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "建立 RunInference 管道"
      ],
      "metadata": {
        "id": "euvWGqu5jmfp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sklearn_model_handler = SklearnModelHandlerNumpy(model_uri=five_times_model_filename)\n",
        "\n",
        "# 設定 Dataflow 管道選項，並指定暫存位置。\n",
        "pipeline_options = PipelineOptions().from_dictionary(\n",
        "                                      {'temp_location': f'gs://{bucket}/tmp'})\n",
        "\n",
        "# 定義 BigQuery 資料表規格。\n",
        "table_name = 'maths_problems_1'\n",
        "table_spec = f'{project}:maths.{table_name}'\n",
        "\n",
        "with beam.Pipeline(options=pipeline_options) as p:\n",
        "  (\n",
        "      p\n",
        "      | \"從 BigQuery 讀取資料\" >> beam.io.ReadFromBigQuery(table=table_spec)\n",
        "      | \"提取輸入值\" >> beam.Map(lambda x: [x['value']])\n",
        "      | \"執行 Sklearn 推論\" >> RunInference(model_handler=sklearn_model_handler)\n",
        "      | beam.Map(print)\n",
        "  )\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIUAvCTUg11L",
        "outputId": "1e131a56-4b3e-4794-a147-e9d06027e416"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'apache_beam.io.gcp.bigquery_read_internal._PassThroughThenCleanup.expand.<locals>.RemoveExtractedFiles'>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PredictionResult(example=[105.0], inference=array([525.]), model_id='sklearn_5x_model.pkl')\n",
            "PredictionResult(example=[108.0], inference=array([540.]), model_id='sklearn_5x_model.pkl')\n",
            "PredictionResult(example=[1013.0], inference=array([5065.]), model_id='sklearn_5x_model.pkl')\n",
            "PredictionResult(example=[1000.0], inference=array([5000.]), model_id='sklearn_5x_model.pkl')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 法2: 讀取鍵值資料進行預測"
      ],
      "metadata": {
        "id": "NwzCo6gzhklI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sklearn_model_handler = SklearnModelHandlerNumpy(model_uri=five_times_model_filename)\n",
        "keyed_sklearn_model_handler = KeyedModelHandler(sklearn_model_handler)\n",
        "\n",
        "# 設定 Dataflow 管道選項，並指定暫存位置。\n",
        "pipeline_options = PipelineOptions().from_dictionary(\n",
        "                                      {'temp_location': f'gs://{bucket}/tmp'})\n",
        "\n",
        "with beam.Pipeline(options=pipeline_options) as p:\n",
        "  (\n",
        "  p\n",
        "  | \"從 BigQuery 讀取資料\" >> beam.io.ReadFromBigQuery(table=table_spec)\n",
        "  | \"提取輸入值\" >> beam.Map(lambda x: (x['key'], [x['value']]))\n",
        "  | \"執行 Sklearn 推論\" >> RunInference(model_handler=keyed_sklearn_model_handler)\n",
        "  | beam.Map(print)\n",
        "  )\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2kPOTwChpOx",
        "outputId": "5229a52c-ef03-428b-cabc-a5906e9408f4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'apache_beam.io.gcp.bigquery_read_internal._PassThroughThenCleanup.expand.<locals>.RemoveExtractedFiles'>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('first_example', PredictionResult(example=[105.0], inference=array([525.]), model_id='sklearn_5x_model.pkl'))\n",
            "('second_example', PredictionResult(example=[108.0], inference=array([540.]), model_id='sklearn_5x_model.pkl'))\n",
            "('fourth_example', PredictionResult(example=[1013.0], inference=array([5065.]), model_id='sklearn_5x_model.pkl'))\n",
            "('third_example', PredictionResult(example=[1000.0], inference=array([5000.]), model_id='sklearn_5x_model.pkl'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 法3: 建立多模型管道進行預測"
      ],
      "metadata": {
        "id": "LJpz924vkhRm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Tuple\n",
        "\n",
        "def format_output(run_inference_output) -> str:\n",
        "  \"\"\"從 RunInference 的輸出提取 scikit-learn 預測結果。\"\"\"\n",
        "  key, prediction_result = run_inference_output\n",
        "  example = prediction_result.example[0]\n",
        "  prediction = prediction_result.inference[0]\n",
        "  return f\"鍵值 = {key}, 範例 = {example} -> 預測結果 {prediction}\"\n",
        "\n",
        "five_times_model_handler = KeyedModelHandler(\n",
        "    SklearnModelHandlerNumpy(model_uri=five_times_model_filename))\n",
        "ten_times_model_handler = KeyedModelHandler(\n",
        "    SklearnModelHandlerNumpy(model_uri=ten_times_model_filename))\n",
        "\n",
        "# 設定 Dataflow 管道選項，並指定暫存位置。\n",
        "pipeline_options = PipelineOptions().from_dictionary(\n",
        "                                      {'temp_location': f'gs://{bucket}/tmp'})\n",
        "\n",
        "with beam.Pipeline(options=pipeline_options) as p:\n",
        "  inputs = (p\n",
        "    | \"從 BigQuery 讀取資料\" >> beam.io.ReadFromBigQuery(table=table_spec))\n",
        "\n",
        "  five_times = (inputs\n",
        "    | \"提取 5 倍運算\" >> beam.Map(lambda x: ('{} {}'.format(x['key'], '* 5'), [x['value']]))\n",
        "    | \"執行 5 倍推論\" >> RunInference(model_handler = five_times_model_handler))\n",
        "\n",
        "  ten_times = (inputs\n",
        "    | \"提取 10 倍運算\" >> beam.Map(lambda x: ('{} {}'.format(x['key'], '* 10'), [x['value']]))\n",
        "    | \"執行 10 倍推論\" >> RunInference(model_handler = ten_times_model_handler))\n",
        "\n",
        "  _ = ((five_times, ten_times)\n",
        "    | \"合併結果\" >> beam.Flatten()\n",
        "    | \"格式化輸出\" >> beam.Map(format_output)\n",
        "    | \"輸出結果\" >> beam.Map(print))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgMjKK7Kjzal",
        "outputId": "b4383396-cc5f-48a4-c425-d1a220c538ae"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'apache_beam.io.gcp.bigquery_read_internal._PassThroughThenCleanup.expand.<locals>.RemoveExtractedFiles'>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "鍵值 = first_example * 5, 範例 = 105.0 -> 預測結果 525.0\n",
            "鍵值 = second_example * 5, 範例 = 108.0 -> 預測結果 540.0\n",
            "鍵值 = fourth_example * 5, 範例 = 1013.0 -> 預測結果 5065.0\n",
            "鍵值 = third_example * 5, 範例 = 1000.0 -> 預測結果 5000.0\n",
            "鍵值 = first_example * 10, 範例 = 105.0 -> 預測結果 1050.0\n",
            "鍵值 = second_example * 10, 範例 = 108.0 -> 預測結果 1080.0\n",
            "鍵值 = fourth_example * 10, 範例 = 1013.0 -> 預測結果 10130.0\n",
            "鍵值 = third_example * 10, 範例 = 1000.0 -> 預測結果 10000.0\n"
          ]
        }
      ]
    }
  ]
}